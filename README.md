# ğŸš€ Workshop-genAI

A hands-on Generative AI Workshop project demonstrating how to build real-world LLM applications using FastAPI, Groq/OpenAI APIs, and structured AI pipelines.

---

## ğŸ“Œ Overview

Workshop-genAI is a practical implementation project designed to teach:

- Large Language Model (LLM) integration
- Prompt engineering
- FastAPI backend development
- Modular AI architecture
- Retrieval-Augmented Generation (RAG)
- AI evaluation techniques

This repository is structured as workshop modules, each building on the previous one.

---

## ğŸ§  Workshop Modules

### ğŸ“¦ Module 1 â€“ AI Concept Explainer
- Prompt-based system
- Multiple explanation modes (Shakespeare, Pirate, Bandit)
- Demonstrates system + user prompt control

### ğŸ“¦ Module 2 â€“ Structured Answer Generator
- FastAPI application
- Returns structured JSON responses
- Basic LLM integration

### ğŸ“¦ Module 3 â€“ LLM Application Architecture
- Clean layered architecture
- input_layer.py
- prompt_layer.py
- llm_layer.py
- post_processing.py
- pipeline.py
- Separation of concerns (real-world AI system design)

### ğŸ“¦ Module 4 â€“ Evaluation System
- Output validation
- Structured scoring
- Basic AI response evaluation methods

### ğŸ“¦ Module 5 â€“ RAG (Retrieval-Augmented Generation)
- Keyword-based retrieval
- knowledge_base/ folder
- retriever.py
- rag_pipeline.py
- LiteLLM integration
- CLI-based interactive Q&A

---

## ğŸ› ï¸ Tech Stack

- Python
- FastAPI
- Groq API
- OpenAI API
- LiteLLM
- Uvicorn
- VS Code

---

## ğŸ“ Project Structure

```
Workshop-genAI/
â”‚
â”œâ”€â”€ m1-ai-concept-explainer/
â”œâ”€â”€ m2-structured_ans_generator/
â”œâ”€â”€ m3-architecture/
â”œâ”€â”€ m4-evalution/
â”œâ”€â”€ m5-rag/
â”‚   â”œâ”€â”€ knowledge_base/
â”‚   â”œâ”€â”€ retriever.py
â”‚   â”œâ”€â”€ llm_layer.py
â”‚   â”œâ”€â”€ rag_pipeline.py
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation Guide

### 1ï¸âƒ£ Clone the Repository

```
git clone https://github.com/Chethumalli/Workshop-genAI.git
cd Workshop-genAI
```

### 2ï¸âƒ£ Create Virtual Environment

Windows:
```
python -m venv venv
venv\Scripts\activate
```

Mac/Linux:
```
python3 -m venv venv
source venv/bin/activate
```

### 3ï¸âƒ£ Install Dependencies

```
pip install -r requirements.txt
```

### 4ï¸âƒ£ Setup Environment Variables

Create a `.env` file in root directory:

```
GROQ_API_KEY=your_groq_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
```

---

## â–¶ï¸ Running Applications

### For FastAPI modules:

```
uvicorn app:app --reload
```

Open:
- http://127.0.0.1:8000
- http://127.0.0.1:8000/docs

### For RAG CLI module:

```
python main.py
```

---

## ğŸ” How It Works

1. User enters prompt
2. Input layer validates data
3. Prompt layer constructs structured prompt
4. LLM layer calls Groq/OpenAI
5. Post-processing formats output
6. Final structured response is returned

For RAG:
1. Query entered
2. Retriever searches knowledge base
3. Retrieved context injected into prompt
4. LLM generates context-aware answer

---

## ğŸš€ Key Learnings

- Prompt engineering controls output
- Architecture matters in AI systems
- RAG improves factual accuracy
- Modular design makes AI scalable
- Clean separation of layers prevents chaos

---

## ğŸŒŸ Future Improvements

- Vector database integration (FAISS / Pinecone)
- Docker support
- Frontend UI
- Cloud deployment
- Streaming responses
- Authentication system
- Fine-tuned custom models

---

## ğŸ¤ Contribution

1. Fork the repository
2. Create feature branch
3. Commit changes
4. Push branch
5. Open Pull Request

---

## ğŸ‘¨â€ğŸ’» Author

Chethan Malli  
AI & ML Enthusiast  
GitHub: https://github.com/Chethumalli

---

â­ If this workshop helped you, please star the repository!

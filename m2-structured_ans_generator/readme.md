# ğŸ§© Module 2 â€“ Structured Answer Generator

## ğŸ“Œ Overview

This module builds a **Structured Response Generator** using:

- âš¡ LiteLLM
- ğŸ”¥ Groq API
- ğŸ§  Prompt Engineering
- ğŸ¯ Deterministic prompting
- ğŸ“¦ Controlled output formatting

The goal of this module is to generate **clean, structured, production-style AI responses** instead of raw unformatted text.

This simulates how real-world AI systems generate predictable, consistent outputs.

---

## ğŸš€ What This Module Demonstrates

âœ” Separation of system and user prompts  
âœ” Controlled output format (headings, bullets, JSON-style structure)  
âœ” Deterministic prompting for consistent responses  
âœ” Production-ready prompt design  
âœ” Secure API key management using `.env`  

---

## ğŸ›  Tech Stack

| Technology | Purpose |
|------------|----------|
| ğŸ Python | Core programming |
| âš¡ LiteLLM | Model abstraction layer |
| ğŸ”¥ Groq API | LLM provider |
| ğŸ“¦ python-dotenv | Environment variable management |

---

## ğŸ“‚ File Structure

```
Module-2/
â”‚
â”œâ”€â”€ structured_generator.py   # Main structured response generator
â”œâ”€â”€ requirements.txt          # Project dependencies
â”œâ”€â”€ .env                      # API keys (not pushed to GitHub)
â””â”€â”€ README.md                 # Documentation
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

###  Add Environment Variables

Create a `.env` file in the root directory:

```env
GROQ_API_KEY=your_key_here
MODEL_NAME=groq/llama-3.1-8b-instant
```

âš ï¸ Never push your `.env` file to GitHub.

---

###  Run the Generator

```bash
python app.py
```

---

## ğŸ§  How It Works

1. A user question is passed to the script.
2. A **system prompt** defines strict formatting rules.
3. The model generates output in a structured format.
4. The script prints a clean, controlled response.

---

## ğŸ§¾ Example Output Format

Instead of random paragraphs, the output follows a structured format like:

```
Title: Topic Name

Definition:
Short explanation

Key Points:
- Point 1
- Point 2
- Point 3

Conclusion:
Short summary
```

This ensures:
- Predictable results  
- Clean formatting  
- Production-ready AI output  

---

## ğŸ¯ Why Structured Prompting Matters

In real AI systems:

- Unstructured outputs are hard to parse
- Structured outputs are easier to store in databases
- Deterministic prompting improves reliability
- Consistent formatting improves user experience

This module demonstrates how production AI systems control LLM behavior.

---

## ğŸ”® Possible Improvements

- Add JSON response mode  
- Convert to FastAPI endpoint  
- Add logging  
- Add temperature control  
- Deploy as microservice  
- Add retry & error handling  

---

## ğŸ‘¨â€ğŸ’» Author

Chethan Malli  
AI & ML Enthusiast  
Building production-ready AI systems ğŸš€

---

â­ If this module helped you understand structured prompting, give the repo a star!

# ğŸš€ Workshop-genAI  

![Python](https://img.shields.io/badge/Python-3.10+-blue?style=for-the-badge&logo=python)
![FastAPI](https://img.shields.io/badge/FastAPI-Backend-green?style=for-the-badge&logo=fastapi)
![LLM](https://img.shields.io/badge/LLM-Groq%20%7C%20OpenAI-orange?style=for-the-badge)
![Status](https://img.shields.io/badge/Status-Active-success?style=for-the-badge)

---

## ğŸ“Œ About The Project  

**Workshop-genAI** is a hands-on implementation repository built during a Generative AI Workshop.  

This project demonstrates how to integrate **Large Language Models (LLMs)** into real-world backend systems using **FastAPI** and modern AI APIs like **Groq** and **OpenAI**.

> ğŸ¯ Goal: Learn how modern AI applications like ChatGPT are built â€” and build one yourself.

---

## ğŸ§  What This Project Covers  

- ğŸ¤– Understanding Large Language Models (LLMs)  
- âš¡ FastAPI backend development  
- ğŸ”¥ Groq / OpenAI API integration  
- ğŸ§  Prompt engineering basics  
- ğŸ›  Building AI-powered applications  

---

## ğŸ›  Tech Stack  

| Technology       | Purpose                      |
|------------------|-----------------------------|
| ğŸ Python        | Core programming             |
| âš¡ FastAPI       | Backend API framework        |
| ğŸ§  Groq / OpenAI | LLM integration              |
| ğŸ”— REST APIs     | Communication layer          |
| ğŸ–¥ VS Code        | Development environment      |

---

## ğŸ“‚ Project Structure  

```bash
Workshop-genAI/
â”‚
â”œâ”€â”€ app.py              # Main FastAPI application
â”œâ”€â”€ requirements.txt    # Project dependencies
â”œâ”€â”€ README.md           # Documentation
â””â”€â”€ .env                # API keys (not included in repo)
```

---

## âš™ï¸ Installation & Setup  

### 1ï¸âƒ£ Clone the Repository  

```bash
git clone https://github.com/Chethumalli/Workshop-genAI.git
cd Workshop-genAI
```

### 2ï¸âƒ£ Create Virtual Environment  

```bash
python -m venv venv
venv\Scripts\activate   # Windows
```

For macOS/Linux:

```bash
source venv/bin/activate
```

### 3ï¸âƒ£ Install Dependencies  

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Add API Key  

Create a `.env` file in the root directory:

```env
GROQ_API_KEY=your_api_key_here
```

(or use `OPENAI_API_KEY` if using OpenAI)

### 5ï¸âƒ£ Run the Application  

```bash
uvicorn app:app --reload
```

Now open:

```
http://127.0.0.1:8000
```

Swagger API documentation:

```
http://127.0.0.1:8000/docs
```

---

## ğŸ”„ How It Works  

1. User sends a prompt  
2. FastAPI backend receives the request  
3. Backend calls Groq/OpenAI API  
4. LLM generates response  
5. API returns structured JSON response  

This is the same architecture used in modern AI applications.

---

## ğŸ”® Future Enhancements  

- ğŸŒ Cloud deployment (AWS / Render / Railway)  
- ğŸ’¬ Frontend UI integration  
- ğŸ” Authentication system  
- ğŸ“Š Logging & analytics  
- ğŸ³ Docker support  
- ğŸ§  Fine-tuned models  

---

## ğŸ¤ Contributing  

Contributions are welcome!

1. Fork the repository  
2. Create a feature branch  
3. Commit your changes  
4. Push to GitHub  
5. Open a Pull Request  

---

## ğŸ‘¨â€ğŸ’» Author  

**Chethan Malli**  
AI & ML Enthusiast  
Building AI-powered systems  

GitHub: https://github.com/Chethumalli  

---

â­ If you found this project useful, consider giving it a star!
